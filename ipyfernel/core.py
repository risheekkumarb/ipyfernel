"""Main(/all) routines for `ipyfernel`"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['gip', 'register_remote_kernel', 'set_ssh_config', 'ipf_startup', 'ipf_exec', 'ipf_shutdown',
           'connect_existing_kernel', 'start_remote', 'stop_remote', 'remote', 'local', 'set_sticky', 'unset_sticky']

# %% ../nbs/00_core.ipynb 4
from jupyter_client.manager import KernelManager
from jupyter_client.kernelspec import KernelSpecManager
import subprocess 
from IPython.display import display, Image
import base64
from pathlib import Path
from IPython.core.magic import register_line_magic, register_line_cell_magic
import json

# %% ../nbs/00_core.ipynb 6
def register_remote_kernel(
    remote_python="/path/to/python",   # Full path of Python executable to run on remote system.
    kernel_name="ipyf_remote_kernel",  # Any old name will do. This is fine.
    display_name="Remote Python",      # This is just what you'll see when you look at a list.
    ssh_host_alias="remote_server_sshpyk", # Same alias as was used in writing to ssh config file.
    remote_kernel_name="python3",      # Typical for Jupiter.
    language="python",                 # Probably want to leave this unless you want to try R.
    verbose=True                       # Print extra info.
    ):
    "registers which python kernel will be used on remote machine"
    ksm = KernelSpecManager()
    registered_names = list(ksm.get_all_specs().keys())
    if kernel_name in registered_names: 
        if verbose: print(f"{kernel_name} is already a registered kernel") 
    else: 
        if verbose: print(f"{kernel_name} is not a registered kernel. We need to add it") 
        subprocess.run(["sshpyk", "add", "--kernel-name", kernel_name,
            "--display-name", display_name, "--remote-python", remote_python, "--ssh-host-alias", ssh_host_alias,
            "--remote-kernel-name", remote_kernel_name, "--language", language
        ])
        if verbose: print("Success.")


# %% ../nbs/00_core.ipynb 8
def set_ssh_config(
    port:int,                       # Port number on proxy server (e.g. bore.pub)
    user:str="",                    # Username on remote system.
    alias="remote_server_sshpyk",   # Default alias for `sshpyk`, leave it alone
    proxyname="bore.pub",           # Have tested this with bore
    config_path="~/.ssh/config",    # Shouldn't need to change this.
    ):
    "(called by ipf_startup) sets up user's ssh .config file with info used later"
    config_path = Path(config_path).expanduser()
    if not config_path.exists(): config_path.touch()
    text = config_path.read_text()
    if f"Host {alias}" not in text: 
        assert user != "", "Must specify username when creating ~/.ssh/config info"
        block = f"""
Host {alias}
    HostName {proxyname}
    Port {port}
    User {user}
    BatchMode yes
    ControlMaster auto
    ControlPath ~/.ssh/sshpyk_%r@%h_%p
    ControlPersist 10m
    StrictHostKeyChecking no
    UserKnownHostsFile /dev/null
"""
        config_path.write_text(text + block)
    else:
        lines = text.splitlines()
        in_target_block = False
        for i, line in enumerate(lines):
            if line.startswith("Host "):
                in_target_block = (line == f"Host {alias}")
            elif in_target_block and line.strip().startswith("Port "):
                lines[i] = f"    Port {port}"
            elif proxyname and in_target_block and line.strip().startswith("HostName "):
                lines[i] = f"    HostName {proxyname}"
            elif user and in_target_block and line.strip().startswith("User "):
                lines[i] = f"    User {user}"
        config_path.write_text("\n".join(lines) + "\n")
    print(f'{config_path} file updated.') 

# %% ../nbs/00_core.ipynb 11
_ipf_km, _ipf_kc = None, None            # "ipf" = "ipyfernel" ;-) 
def ipf_startup(kernel_name="ipyf_remote_kernel"):  
    "Start up the remote kernel"
    global _ipf_km, _ipf_kc 
    if _ipf_km is None and _ipf_kc is None: #only do this at startup
        # Create kernels paremt folder if it doesn't exist (like in solveit)
        Path("~/.local/share/jupyter/runtime").expanduser().mkdir(parents=True, exist_ok=True)
        _ipf_km = KernelManager(kernel_name=kernel_name)
        _ipf_km.start_kernel()
        _ipf_kc = _ipf_km.client()
        _ipf_kc.start_channels()
        _ipf_kc.wait_for_ready(timeout=30)
        print("Success: remote kernel started")
    else: 
        print("ipf_startup: already running")

# %% ../nbs/00_core.ipynb 13
def _output_hook(
    msg,   #  Message obtained from remote execution
    ):
    "How to handle output from the remote kernel."
    mt = msg["msg_type"]
    content = msg.get("content", {})
    if mt == "stream":
        print(content["text"], end="", flush=True)
    elif mt == "error":
        print('\n'.join(content.get("traceback", [])))
    elif mt in ("display_data", "update_display_data"):
        data = content.get("data", {})
        if "image/png" in data:
            display(Image(base64.b64decode(data["image/png"])))
        elif "text/plain" in data:
            print(data["text/plain"])

# %% ../nbs/00_core.ipynb 14
def ipf_exec(
    code:str,           # Code to be executed
    verbose=False,      # Return details about remote execution.
    ):
    "Execute code on the remote kernel." 
    assert _ipf_kc is not None, "ipf_exec: need to run ipf_startup() first"
    result = _ipf_kc.execute_interactive(code=code, output_hook=_output_hook)
    _ipf_kc.last_result = result  # stash it for optional inspection later
    if verbose: return result

# %% ../nbs/00_core.ipynb 16
def ipf_shutdown(verbose=True):
    "Terminates the remote kernel"
    global _ipf_km, _ipf_kc
    if verbose: print("Shutting down remote kernel") # Note: Could make say if remote kernel is not even running.
    try:
        if _ipf_kc is not None: _ipf_kc.stop_channels()
        if _ipf_km is not None: _ipf_km.shutdown_kernel(now=True)  # 'now=True' forces immediate shutdown
    except: pass  # Don't hang on errors
    _ipf_km, _ipf_kc = None, None

# %% ../nbs/00_core.ipynb 18
def _setup_tunnels(remote_ports, ssh_host="remote_server_sshpyk"):
    """Create SSH tunnels for each port"""
    tunnels = []
    for local_port, remote_port in remote_ports.items():
        cmd = ['ssh', '-N', '-L', f'{local_port}:127.0.0.1:{remote_port}', ssh_host]
        proc = subprocess.Popen(cmd)
        tunnels.append(proc)
    return tunnels

# %% ../nbs/00_core.ipynb 19
def _prepare_kaggle_connection(ngrok_host, ngrok_port, ssh_alias="remote_server_sshpyk"):
    """Prepare connection to existing Kaggle kernel"""
    set_ssh_config(port=ngrok_port, user='root', alias=ssh_alias, proxyname=ngrok_host)
    result = subprocess.run(['ssh', ssh_alias, 'cat /root/.local/share/jupyter/runtime/kernel-*.json'], 
                       capture_output=True, text=True)
    if result.returncode != 0:
        raise RuntimeError(f"Failed to fetch kernel info: {result.stderr}")
    kernel_dict = json.loads(result.stdout)
    remote_ports = {v:v for k,v in kernel_dict.items() if '_port' in k}
    _setup_tunnels(remote_ports=remote_ports)
    local_conn = kernel_dict.copy()
    local_conn['ip'] = '127.0.0.1'  # Connect locally through tunnels
    conn_file = Path.home() / '.local/share/jupyter/runtime/kaggle_kernel.json'
    conn_file.parent.mkdir(parents=True, exist_ok=True)
    conn_file.write_text(json.dumps(local_conn, indent=2))
    print('Successfully created connection file and forwarded ports!')
    return conn_file

# %% ../nbs/00_core.ipynb 20
def connect_existing_kernel(tunnel, kernel_name="ipyf_remote_kernel"):  
    "Connect to existing remote kernel"
    global _ipf_km, _ipf_kc 
    if _ipf_km is None and _ipf_kc is None: #only do this at startup
        try:
            host, port = tunnel.split(':')
            conn_file = _prepare_kaggle_connection(host, int(port))
        except ValueError:
            raise ValueError(f"Failed to extract host and port from tunnel (expects 'host:port' e.g. '2.tcp.ngrok.io:13103'): {tunnel}")
        _ipf_km = KernelManager(connection_file=str(conn_file))
        _ipf_km.load_connection_file()
        _ipf_kc = _ipf_km.client()
        _ipf_kc.start_channels()
        _ipf_kc.wait_for_ready(timeout=10)
        print(f"Success: connected to remote kernel via {tunnel}")
    else: 
        print("connect_existing_kernel: already connected")
    

# %% ../nbs/00_core.ipynb 23
def start_remote(port, user=""):
    "Configure ssh connection to remote server and start remote server"
    set_ssh_config(port, user=user) 
    try: 
        ipf_startup()
    except Exception as e: 
        print(f"Error starting up remote kernel: {e}") 
        return 

# %% ../nbs/00_core.ipynb 25
def stop_remote():
    "shutdown remote server"
    unset_sticky()  # get rid of any input transformers (see below) 
    ipf_shutdown()

# %% ../nbs/00_core.ipynb 28
_skip_next = False  # This is used in conjunction with %%local, below

def _execute_remotely(lines:list[str]):
    "Take commands from magics and send to ipf_exec"
    global _skip_next
    if _skip_next:
        _skip_next = False
        return lines
    code = ''.join(lines)
    if 'get_ipython()' in code: return lines  # let solveit internals pass through
    # Make sure our controls execute locally
    if code.strip().startswith(('%local', '%%local', 'start_remote(', 'stop_remote(', 'set_remote(', 'unset_remote(', 'set_sticky(','unset_sticky(')):
        return lines
    return [f"ipf_exec({repr(code)})\n"]

# %% ../nbs/00_core.ipynb 29
@register_line_cell_magic
def remote(line, cell=None):
    "remote exeuction: works as %remote and as %%remote" 
    ipf_exec(cell if cell else line)

# %% ../nbs/00_core.ipynb 32
@register_line_cell_magic
def local(line, cell=None):
    "local execution: works as %local and as %%local"
    global _skip_next
    _skip_next = True
    get_ipython().run_cell(cell if cell else line) 

# %% ../nbs/00_core.ipynb 36
gip = get_ipython()

def set_sticky():
    "Makes code cells execute remotely, via input transformer"
    assert _ipf_kc is not None, "Need an active remote kernel connection" 
    for f in gip.input_transformers_cleanup[:]:   # gaurd against appending twice
        if getattr(f, '__name__', '') == '_execute_remotely':
            print("Already executing remotely") 
            return 
    gip.input_transformers_cleanup.append(_execute_remotely)
    print('Code cells will now execute remotely.')

# %% ../nbs/00_core.ipynb 37
def unset_sticky():
    "Un-sticks remote execution for code cells" 
    for f in gip.input_transformers_cleanup[:]:  
        if getattr(f, '__name__', '') == '_execute_remotely':
            gip.input_transformers_cleanup.remove(f)
    print("Code cells will now run locally.") 


